# Tag Suggestion System Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Implement ML-powered tag suggestion system that suggests tags for uploaded images using a hybrid approach (custom theme model + Danbooru model) with human review workflow.

**Architecture:** Database tables for storing suggestions → API endpoints for fetching/reviewing → Background Arq job for ML inference → Mock ML models initially (replace with real models in Phase 2).

**Tech Stack:** FastAPI, SQLModel, Alembic (migrations), Arq (background jobs), Pytest, MariaDB

**Design Document:** `docs/plans/2025-12-04-tag-suggestion-system-design.md`

---

## Phase 1: Database Schema & Models

### Task 1.1: Create TagSuggestion Model

**Files:**
- Create: `app/models/tag_suggestion.py`
- Test: `tests/models/test_tag_suggestion.py`

**Step 1: Write the failing test**

Create test file:

```python
# tests/models/test_tag_suggestion.py

import pytest
from datetime import datetime
from app.models.tag_suggestion import TagSuggestion
from app.models.image import Images
from app.models.tag import Tags
from app.models.user import Users


def test_tag_suggestion_model_creation(db_session):
    """Test creating a TagSuggestion instance"""
    # Create dependencies
    user = Users(username="testuser", email="test@example.com", password="hashed")
    db_session.add(user)
    db_session.flush()

    image = Images(
        filename="test",
        ext="jpg",
        user_id=user.user_id,
        md5_hash="abc123",
        filesize=1024,
        width=800,
        height=600
    )
    db_session.add(image)
    db_session.flush()

    tag = Tags(title="long hair", type=1, user_id=user.user_id)
    db_session.add(tag)
    db_session.flush()

    # Create suggestion
    suggestion = TagSuggestion(
        image_id=image.image_id,
        tag_id=tag.tag_id,
        confidence=0.92,
        model_source="custom_theme",
        model_version="v1",
        status="pending"
    )
    db_session.add(suggestion)
    db_session.commit()

    # Verify
    assert suggestion.suggestion_id is not None
    assert suggestion.confidence == 0.92
    assert suggestion.status == "pending"
    assert suggestion.created_at is not None


def test_tag_suggestion_unique_constraint(db_session):
    """Test that same tag cannot be suggested twice for same image"""
    user = Users(username="testuser", email="test@example.com", password="hashed")
    db_session.add(user)
    db_session.flush()

    image = Images(
        filename="test",
        ext="jpg",
        user_id=user.user_id,
        md5_hash="abc123",
        filesize=1024,
        width=800,
        height=600
    )
    db_session.add(image)
    db_session.flush()

    tag = Tags(title="long hair", type=1, user_id=user.user_id)
    db_session.add(tag)
    db_session.flush()

    # First suggestion
    suggestion1 = TagSuggestion(
        image_id=image.image_id,
        tag_id=tag.tag_id,
        confidence=0.9,
        model_source="custom_theme",
        model_version="v1",
        status="pending"
    )
    db_session.add(suggestion1)
    db_session.commit()

    # Second suggestion (duplicate)
    suggestion2 = TagSuggestion(
        image_id=image.image_id,
        tag_id=tag.tag_id,
        confidence=0.95,
        model_source="danbooru",
        model_version="wd14_v2",
        status="pending"
    )
    db_session.add(suggestion2)

    # Should raise IntegrityError due to UNIQUE constraint
    with pytest.raises(Exception):  # IntegrityError or similar
        db_session.commit()
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/models/test_tag_suggestion.py -v`

Expected: FAIL with "ModuleNotFoundError: No module named 'app.models.tag_suggestion'"

**Step 3: Write minimal implementation**

Create model file:

```python
# app/models/tag_suggestion.py

"""
Tag Suggestion Model

Stores ML-generated tag suggestions for images that require human review.
"""

from datetime import datetime
from typing import Optional

from sqlmodel import SQLModel, Field, Column
from sqlalchemy import Enum as SQLEnum, UniqueConstraint


class TagSuggestion(SQLModel, table=True):
    """
    Tag suggestions generated by ML models.

    Lifecycle:
    1. ML model generates suggestion → status='pending'
    2. User approves → status='approved', TagLink created
    3. User rejects → status='rejected'
    """

    __tablename__ = "tag_suggestions"
    __table_args__ = (
        UniqueConstraint('image_id', 'tag_id', name='uq_image_tag'),
    )

    suggestion_id: Optional[int] = Field(default=None, primary_key=True)
    image_id: int = Field(foreign_key="images.image_id", index=True)
    tag_id: int = Field(foreign_key="tags.tag_id", index=True)
    confidence: float = Field(ge=0.0, le=1.0)
    model_source: str = Field(
        sa_column=Column(
            SQLEnum('custom_theme', 'danbooru', name='model_source_enum'),
            nullable=False
        )
    )
    model_version: str = Field(max_length=50)
    status: str = Field(
        default='pending',
        sa_column=Column(
            SQLEnum('pending', 'approved', 'rejected', name='suggestion_status_enum'),
            nullable=False
        ),
        index=True
    )
    created_at: datetime = Field(default_factory=datetime.utcnow)
    reviewed_at: Optional[datetime] = None
    reviewed_by_user_id: Optional[int] = Field(default=None, foreign_key="users.user_id")
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/models/test_tag_suggestion.py -v`

Expected: PASS (both tests)

**Step 5: Commit**

```bash
git add app/models/tag_suggestion.py tests/models/test_tag_suggestion.py
git commit -m "feat: add TagSuggestion model with tests

- Create TagSuggestion SQLModel for storing ML-generated tag suggestions
- Add unique constraint on (image_id, tag_id)
- Add status enum (pending, approved, rejected)
- Add model_source enum (custom_theme, danbooru)
- Include comprehensive tests for model creation and constraints"
```

---

### Task 1.2: Create TagMapping Model

**Files:**
- Create: `app/models/tag_mapping.py`
- Test: `tests/models/test_tag_mapping.py`

**Step 1: Write the failing test**

```python
# tests/models/test_tag_mapping.py

from app.models.tag_mapping import TagMapping
from app.models.tag import Tags
from app.models.user import Users


def test_tag_mapping_creation(db_session):
    """Test creating a TagMapping instance"""
    user = Users(username="testuser", email="test@example.com", password="hashed")
    db_session.add(user)
    db_session.flush()

    tag = Tags(title="long hair", type=1, user_id=user.user_id)
    db_session.add(tag)
    db_session.flush()

    mapping = TagMapping(
        external_tag="long_hair",
        external_source="danbooru",
        internal_tag_id=tag.tag_id,
        confidence=1.0
    )
    db_session.add(mapping)
    db_session.commit()

    assert mapping.mapping_id is not None
    assert mapping.external_tag == "long_hair"
    assert mapping.internal_tag_id == tag.tag_id


def test_tag_mapping_null_internal_tag(db_session):
    """Test mapping with null internal_tag_id (means ignore this tag)"""
    mapping = TagMapping(
        external_tag="1girl",  # Danbooru tag we don't use
        external_source="danbooru",
        internal_tag_id=None,  # Ignore this tag
        confidence=1.0
    )
    db_session.add(mapping)
    db_session.commit()

    assert mapping.internal_tag_id is None
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/models/test_tag_mapping.py -v`

Expected: FAIL with "ModuleNotFoundError: No module named 'app.models.tag_mapping'"

**Step 3: Write minimal implementation**

```python
# app/models/tag_mapping.py

"""
Tag Mapping Model

Maps external tag vocabularies (e.g., Danbooru) to internal tags.
"""

from datetime import datetime
from typing import Optional

from sqlmodel import SQLModel, Field, Column
from sqlalchemy import Enum as SQLEnum, UniqueConstraint


class TagMapping(SQLModel, table=True):
    """
    Maps external tags (from Danbooru, etc.) to internal tags.

    If internal_tag_id is NULL, it means "ignore this external tag".
    """

    __tablename__ = "tag_mappings"
    __table_args__ = (
        UniqueConstraint('external_source', 'external_tag', name='uq_external_source_tag'),
    )

    mapping_id: Optional[int] = Field(default=None, primary_key=True)
    external_tag: str = Field(max_length=255)
    external_source: str = Field(
        sa_column=Column(
            SQLEnum('danbooru', 'other', name='external_source_enum'),
            nullable=False
        )
    )
    internal_tag_id: Optional[int] = Field(
        default=None,
        foreign_key="tags.tag_id",
        index=True
    )
    confidence: float = Field(default=1.0, ge=0.0, le=1.0)
    created_by_user_id: Optional[int] = Field(default=None, foreign_key="users.user_id")
    created_at: datetime = Field(default_factory=datetime.utcnow)
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/models/test_tag_mapping.py -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/models/tag_mapping.py tests/models/test_tag_mapping.py
git commit -m "feat: add TagMapping model with tests

- Map external tags (Danbooru) to internal tag IDs
- NULL internal_tag_id means ignore this external tag
- Unique constraint on (external_source, external_tag)"
```

---

### Task 1.3: Create MLModelVersion Model

**Files:**
- Create: `app/models/ml_model_version.py`
- Test: `tests/models/test_ml_model_version.py`

**Step 1: Write the failing test**

```python
# tests/models/test_ml_model_version.py

from app.models.ml_model_version import MLModelVersion


def test_ml_model_version_creation(db_session):
    """Test creating an MLModelVersion instance"""
    model_version = MLModelVersion(
        model_name="custom_theme",
        version="v1",
        file_path="/shuushuu/ml_models/custom_theme/v1/model.onnx",
        is_active=True,
        metrics={"accuracy": 0.85, "precision": 0.82}
    )
    db_session.add(model_version)
    db_session.commit()

    assert model_version.version_id is not None
    assert model_version.is_active is True
    assert model_version.metrics["accuracy"] == 0.85


def test_unique_model_name_version(db_session):
    """Test unique constraint on (model_name, version)"""
    import pytest

    v1 = MLModelVersion(
        model_name="custom_theme",
        version="v1",
        file_path="/path/to/v1",
        is_active=True
    )
    db_session.add(v1)
    db_session.commit()

    # Duplicate
    v1_dup = MLModelVersion(
        model_name="custom_theme",
        version="v1",
        file_path="/path/to/v1_duplicate",
        is_active=False
    )
    db_session.add(v1_dup)

    with pytest.raises(Exception):  # IntegrityError
        db_session.commit()
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/models/test_ml_model_version.py -v`

Expected: FAIL with "ModuleNotFoundError"

**Step 3: Write minimal implementation**

```python
# app/models/ml_model_version.py

"""
ML Model Version Model

Tracks deployed ML model versions for tag suggestion system.
"""

from datetime import datetime
from typing import Optional, Dict, Any

from sqlmodel import SQLModel, Field, Column
from sqlalchemy import UniqueConstraint, JSON


class MLModelVersion(SQLModel, table=True):
    """
    Tracks ML model deployments and versions.

    Workers query for is_active=True to find current model.
    """

    __tablename__ = "ml_model_versions"
    __table_args__ = (
        UniqueConstraint('model_name', 'version', name='uq_model_name_version'),
    )

    version_id: Optional[int] = Field(default=None, primary_key=True)
    model_name: str = Field(max_length=100, index=True)  # 'custom_theme', 'danbooru'
    version: str = Field(max_length=50)  # 'v1', 'v2', 'wd14_v2'
    file_path: str = Field(max_length=500)
    is_active: bool = Field(default=False, index=True)
    deployed_at: datetime = Field(default_factory=datetime.utcnow)
    metrics: Optional[Dict[str, Any]] = Field(
        default=None,
        sa_column=Column(JSON, nullable=True)
    )
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/models/test_ml_model_version.py -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/models/ml_model_version.py tests/models/test_ml_model_version.py
git commit -m "feat: add MLModelVersion model with tests

- Track ML model deployments and versions
- is_active flag determines which version workers load
- Store evaluation metrics as JSON"
```

---

### Task 1.4: Create Alembic Migration

**Files:**
- Create: `alembic/versions/XXXXX_add_tag_suggestion_tables.py`

**Step 1: Generate migration**

Run: `uv run alembic revision --autogenerate -m "add tag suggestion tables"`

**Step 2: Review generated migration**

Open the generated file in `alembic/versions/` and verify it includes:
- `tag_suggestions` table with all columns and constraints
- `tag_mappings` table
- `ml_model_versions` table
- Proper indexes and foreign keys

**Step 3: Apply migration to test database**

Run: `uv run alembic upgrade head`

Expected: Migration applies successfully

**Step 4: Verify tables exist**

Run: `uv run python -c "from app.core.database import engine; from sqlalchemy import inspect; print(inspect(engine).get_table_names())"`

Expected: Output includes `tag_suggestions`, `tag_mappings`, `ml_model_versions`

**Step 5: Commit**

```bash
git add alembic/versions/*_add_tag_suggestion_tables.py
git commit -m "feat: add Alembic migration for tag suggestion tables

- Create tag_suggestions table with unique constraint
- Create tag_mappings table
- Create ml_model_versions table
- Add indexes on commonly queried fields"
```

---

## Phase 2: Pydantic Schemas

### Task 2.1: Create Tag Suggestion Schemas

**Files:**
- Create: `app/schemas/tag_suggestion.py`
- Test: `tests/schemas/test_tag_suggestion_schemas.py`

**Step 1: Write the failing test**

```python
# tests/schemas/test_tag_suggestion_schemas.py

from datetime import datetime
from app.schemas.tag_suggestion import (
    TagSuggestionResponse,
    TagSuggestionsListResponse,
    ReviewSuggestionRequest,
    ReviewSuggestionsRequest
)
from app.schemas.tag import TagResponse


def test_tag_suggestion_response_schema():
    """Test TagSuggestionResponse serialization"""
    tag = TagResponse(tag_id=46, title="long hair", type=1, date_added=datetime.utcnow())

    suggestion = TagSuggestionResponse(
        suggestion_id=1,
        tag=tag,
        confidence=0.92,
        model_source="custom_theme",
        status="pending",
        created_at=datetime.utcnow()
    )

    assert suggestion.suggestion_id == 1
    assert suggestion.tag.title == "long hair"
    assert suggestion.confidence == 0.92


def test_review_suggestion_request_validation():
    """Test ReviewSuggestionRequest validates action"""
    import pytest
    from pydantic import ValidationError

    # Valid
    req = ReviewSuggestionRequest(suggestion_id=1, action="approve")
    assert req.action == "approve"

    # Invalid action
    with pytest.raises(ValidationError):
        ReviewSuggestionRequest(suggestion_id=1, action="invalid")
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/schemas/test_tag_suggestion_schemas.py -v`

Expected: FAIL with "ModuleNotFoundError"

**Step 3: Write minimal implementation**

```python
# app/schemas/tag_suggestion.py

"""
Tag Suggestion Pydantic Schemas

Request/response schemas for tag suggestion API endpoints.
"""

from datetime import datetime
from typing import Literal

from pydantic import BaseModel, Field

from app.schemas.tag import TagResponse


class TagSuggestionResponse(BaseModel):
    """Response schema for a single tag suggestion"""

    suggestion_id: int
    tag: TagResponse
    confidence: float = Field(ge=0.0, le=1.0)
    model_source: Literal["custom_theme", "danbooru"]
    status: Literal["pending", "approved", "rejected"]
    created_at: datetime
    reviewed_at: datetime | None = None

    class Config:
        from_attributes = True


class TagSuggestionsListResponse(BaseModel):
    """Response schema for list of suggestions for an image"""

    image_id: int
    suggestions: list[TagSuggestionResponse]
    total: int
    pending: int
    approved: int
    rejected: int


class ReviewSuggestionRequest(BaseModel):
    """Request schema for reviewing a single suggestion"""

    suggestion_id: int
    action: Literal["approve", "reject"]


class ReviewSuggestionsRequest(BaseModel):
    """Request schema for reviewing multiple suggestions"""

    suggestions: list[ReviewSuggestionRequest]


class ReviewSuggestionsResponse(BaseModel):
    """Response schema for review action"""

    approved: int
    rejected: int
    errors: list[str] = []


class TagSuggestionStatsResponse(BaseModel):
    """Response schema for tag suggestion statistics"""

    total_suggestions: int
    pending: int
    approved: int
    rejected: int
    approval_rate: float
    by_model: dict[str, dict[str, int]]
    top_suggested_tags: list[dict[str, int | str]]


class SuggestionStatusResponse(BaseModel):
    """Response schema for suggestion generation status"""

    status: Literal["queued", "processing", "completed", "failed"]
    pending_count: int
    job_id: str | None = None
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/schemas/test_tag_suggestion_schemas.py -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/schemas/tag_suggestion.py tests/schemas/test_tag_suggestion_schemas.py
git commit -m "feat: add tag suggestion Pydantic schemas

- TagSuggestionResponse for single suggestion
- TagSuggestionsListResponse for list view
- Review request/response schemas
- Stats and status schemas"
```

---

## Phase 3: ML Service (Mock Implementation)

### Task 3.1: Create Mock ML Service

**Files:**
- Create: `app/services/ml_service.py`
- Create: `app/services/tag_resolver.py`
- Test: `tests/services/test_ml_service.py`

**Step 1: Write the failing test**

```python
# tests/services/test_ml_service.py

import pytest
from app.services.ml_service import MLTagSuggestionService


@pytest.mark.asyncio
async def test_ml_service_generate_suggestions():
    """Test ML service generates mock suggestions"""
    service = MLTagSuggestionService()
    await service.load_models()

    # For now, we're using mock models that return predefined suggestions
    suggestions = await service.generate_suggestions("path/to/image.jpg")

    assert isinstance(suggestions, list)
    assert len(suggestions) > 0
    assert "tag_id" in suggestions[0]
    assert "confidence" in suggestions[0]
    assert "model_source" in suggestions[0]


@pytest.mark.asyncio
async def test_ml_service_filters_by_confidence():
    """Test that low confidence suggestions are filtered"""
    service = MLTagSuggestionService()
    await service.load_models()

    suggestions = await service.generate_suggestions(
        "path/to/image.jpg",
        min_confidence=0.8
    )

    # All suggestions should be above threshold
    assert all(s["confidence"] >= 0.8 for s in suggestions)
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/services/test_ml_service.py -v`

Expected: FAIL with "ModuleNotFoundError"

**Step 3: Write minimal implementation (MOCK VERSION)**

```python
# app/services/ml_service.py

"""
ML Tag Suggestion Service

PHASE 1: Mock implementation that returns hardcoded suggestions.
PHASE 2: Replace with real model inference.
"""

import asyncio
import random
from typing import List, Dict


class MockModel:
    """Mock ML model for testing"""

    def __init__(self, model_type: str):
        self.model_type = model_type

        # Mock tag predictions (tag_id → confidence)
        if model_type == "custom_theme":
            self.predictions = {
                46: 0.92,   # long hair
                161: 0.88,  # short hair
                25: 0.85,   # blush
                3: 0.75,    # ribbon
                143: 0.82,  # smile
            }
        else:  # danbooru
            self.predictions = {
                46: 0.90,   # long hair (overlap with custom)
                12525: 0.87,  # blue eyes
                169: 0.78,    # blonde hair
            }

    async def predict(self, image_path: str) -> List[Dict]:
        """Mock prediction - returns hardcoded suggestions"""
        # Simulate inference delay
        await asyncio.sleep(0.1)

        # Add some randomness to confidence
        predictions = []
        for tag_id, base_confidence in self.predictions.items():
            confidence = base_confidence + random.uniform(-0.05, 0.05)
            confidence = max(0.0, min(1.0, confidence))  # Clamp to [0, 1]

            predictions.append({
                "tag_id": tag_id,
                "confidence": confidence,
                "model_source": self.model_type
            })

        return predictions


class MLTagSuggestionService:
    """
    ML Tag Suggestion Service

    PHASE 1: Uses mock models
    PHASE 2: Replace with real ONNX/PyTorch models
    """

    def __init__(self):
        self.custom_model = None
        self.danbooru_model = None

    async def load_models(self):
        """Load ML models into memory"""
        # PHASE 1: Load mock models
        self.custom_model = MockModel("custom_theme")
        self.danbooru_model = MockModel("danbooru")

        # PHASE 2: Load real models
        # self.custom_model = ONNXModel("/path/to/custom_theme.onnx")
        # self.danbooru_model = ONNXModel("/path/to/danbooru.onnx")

    async def generate_suggestions(
        self,
        image_path: str,
        min_confidence: float = 0.6
    ) -> List[Dict]:
        """
        Generate tag suggestions for an image.

        Returns list of dicts with keys: tag_id, confidence, model_source
        """
        if not self.custom_model or not self.danbooru_model:
            raise RuntimeError("Models not loaded. Call load_models() first.")

        # Run both models in parallel
        custom_preds, danbooru_preds = await asyncio.gather(
            self.custom_model.predict(image_path),
            self.danbooru_model.predict(image_path)
        )

        # Merge predictions (prioritize custom for themes)
        merged = self._merge_predictions(custom_preds, danbooru_preds)

        # Filter by confidence
        filtered = [
            pred for pred in merged
            if pred["confidence"] >= min_confidence
        ]

        return filtered

    def _merge_predictions(
        self,
        custom_preds: List[Dict],
        danbooru_preds: List[Dict]
    ) -> List[Dict]:
        """
        Merge predictions from both models.

        Strategy: Prioritize custom model predictions, use Danbooru for additional tags.
        """
        # Use dict to deduplicate by tag_id
        merged = {}

        # Add custom predictions first (higher priority)
        for pred in custom_preds:
            merged[pred["tag_id"]] = pred

        # Add Danbooru predictions if not already present
        for pred in danbooru_preds:
            if pred["tag_id"] not in merged:
                merged[pred["tag_id"]] = pred

        return list(merged.values())

    async def cleanup(self):
        """Cleanup resources"""
        self.custom_model = None
        self.danbooru_model = None
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/services/test_ml_service.py -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/services/ml_service.py tests/services/test_ml_service.py
git commit -m "feat: add mock ML tag suggestion service

PHASE 1 implementation:
- Mock models return hardcoded predictions
- Simulates dual-model inference (custom + Danbooru)
- Filters by confidence threshold
- Will be replaced with real models in Phase 2"
```

---

### Task 3.2: Create Tag Relationship Resolver

**Files:**
- Create: `app/services/tag_resolver.py`
- Test: `tests/services/test_tag_resolver.py`

**Step 1: Write the failing test**

```python
# tests/services/test_tag_resolver.py

import pytest
from sqlalchemy.ext.asyncio import AsyncSession
from app.services.tag_resolver import resolve_tag_relationships
from app.models.tag import Tags
from app.models.user import Users


@pytest.mark.asyncio
async def test_resolve_alias_to_canonical_tag(db_session: AsyncSession):
    """Test that alias tags are resolved to canonical tags"""
    user = Users(username="test", email="test@example.com", password="hashed")
    db_session.add(user)
    await db_session.flush()

    # Create canonical tag
    canonical = Tags(tag_id=46, title="long hair", type=1, user_id=user.user_id)
    db_session.add(canonical)
    await db_session.flush()

    # Create alias tag pointing to canonical
    alias = Tags(tag_id=100, title="longhair", type=1, alias=46, user_id=user.user_id)
    db_session.add(alias)
    await db_session.commit()

    # Suggestion with alias tag
    suggestions = [
        {"tag_id": 100, "confidence": 0.9, "model_source": "custom_theme"}
    ]

    resolved = await resolve_tag_relationships(db_session, suggestions)

    # Should resolve to canonical tag
    assert len(resolved) == 1
    assert resolved[0]["tag_id"] == 46  # Canonical tag
    assert resolved[0]["resolved_from_alias"] is True


@pytest.mark.asyncio
async def test_add_parent_tag_from_hierarchy(db_session: AsyncSession):
    """Test that parent tags are added when child tag has high confidence"""
    user = Users(username="test", email="test@example.com", password="hashed")
    db_session.add(user)
    await db_session.flush()

    # Create parent tag
    parent = Tags(tag_id=50, title="hair", type=1, user_id=user.user_id)
    db_session.add(parent)
    await db_session.flush()

    # Create child tag with parent reference
    child = Tags(tag_id=46, title="long hair", type=1, inheritedfrom_id=50, user_id=user.user_id)
    db_session.add(child)
    await db_session.commit()

    suggestions = [
        {"tag_id": 46, "confidence": 0.95, "model_source": "custom_theme"}
    ]

    resolved = await resolve_tag_relationships(db_session, suggestions)

    # Should have both child and parent
    assert len(resolved) == 2
    tag_ids = [s["tag_id"] for s in resolved]
    assert 46 in tag_ids  # Child
    assert 50 in tag_ids  # Parent

    # Parent should have slightly lower confidence
    parent_sugg = next(s for s in resolved if s["tag_id"] == 50)
    assert parent_sugg["confidence"] < 0.95
    assert parent_sugg["from_hierarchy"] is True
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/services/test_tag_resolver.py -v`

Expected: FAIL with "ModuleNotFoundError"

**Step 3: Write minimal implementation**

```python
# app/services/tag_resolver.py

"""
Tag Relationship Resolver

Resolves tag aliases and hierarchies for ML suggestions.
"""

from typing import List, Dict
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.models.tag import Tags


async def resolve_tag_relationships(
    db: AsyncSession,
    suggestions: List[Dict]
) -> List[Dict]:
    """
    Resolve tag aliases and hierarchies.

    - If tag is an alias, replace with canonical tag
    - Optionally add parent tags from hierarchy

    Args:
        db: Database session
        suggestions: List of dicts with keys: tag_id, confidence, model_source

    Returns:
        List of resolved suggestions (may be longer if parent tags added)
    """
    resolved = []

    for sugg in suggestions:
        # Fetch tag to check alias and hierarchy
        result = await db.execute(
            select(Tags).where(Tags.tag_id == sugg["tag_id"])
        )
        tag = result.scalar_one_or_none()

        if not tag:
            # Tag doesn't exist, skip
            continue

        # Resolve alias
        if tag.alias:
            # This tag is an alias, use the canonical tag
            sugg = sugg.copy()  # Don't modify original
            sugg["tag_id"] = tag.alias
            sugg["resolved_from_alias"] = True

            # Update tag reference for hierarchy check
            result = await db.execute(
                select(Tags).where(Tags.tag_id == tag.alias)
            )
            tag = result.scalar_one_or_none()

        resolved.append(sugg)

        # Add parent tag if exists and confidence is high enough
        if tag and tag.inheritedfrom_id and sugg["confidence"] > 0.7:
            parent_sugg = sugg.copy()
            parent_sugg["tag_id"] = tag.inheritedfrom_id
            parent_sugg["confidence"] *= 0.9  # Reduce confidence slightly
            parent_sugg["from_hierarchy"] = True
            resolved.append(parent_sugg)

    return resolved
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/services/test_tag_resolver.py -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/services/tag_resolver.py tests/services/test_tag_resolver.py
git commit -m "feat: add tag relationship resolver service

- Resolve tag aliases to canonical tags
- Add parent tags from hierarchy (inheritedfrom_id)
- Handles missing tags gracefully
- Comprehensive tests for alias and hierarchy resolution"
```

---

## Phase 4: API Endpoints

### Task 4.1: Get Suggestions Endpoint

**Files:**
- Modify: `app/api/v1/images.py` (add new router)
- Test: `tests/api/v1/test_tag_suggestions.py`

**Step 1: Write the failing test**

```python
# tests/api/v1/test_tag_suggestions.py

import pytest
from httpx import AsyncClient
from app.models.image import Images
from app.models.tag import Tags
from app.models.tag_suggestion import TagSuggestion
from app.models.user import Users


@pytest.mark.asyncio
async def test_get_suggestions_for_image(client: AsyncClient, db_session):
    """Test GET /api/v1/images/{image_id}/tag-suggestions"""
    # Create test data
    user = Users(username="test", email="test@example.com", password="hashed")
    db_session.add(user)
    await db_session.flush()

    image = Images(
        filename="test",
        ext="jpg",
        user_id=user.user_id,
        md5_hash="abc123",
        filesize=1024,
        width=800,
        height=600
    )
    db_session.add(image)
    await db_session.flush()

    tag1 = Tags(title="long hair", type=1, user_id=user.user_id)
    tag2 = Tags(title="smile", type=1, user_id=user.user_id)
    db_session.add_all([tag1, tag2])
    await db_session.flush()

    sugg1 = TagSuggestion(
        image_id=image.image_id,
        tag_id=tag1.tag_id,
        confidence=0.92,
        model_source="custom_theme",
        model_version="v1",
        status="pending"
    )
    sugg2 = TagSuggestion(
        image_id=image.image_id,
        tag_id=tag2.tag_id,
        confidence=0.85,
        model_source="custom_theme",
        model_version="v1",
        status="pending"
    )
    db_session.add_all([sugg1, sugg2])
    await db_session.commit()

    # Make request
    response = await client.get(
        f"/api/v1/images/{image.image_id}/tag-suggestions",
        headers={"Authorization": f"Bearer {get_auth_token(user)}"}
    )

    assert response.status_code == 200
    data = response.json()
    assert data["image_id"] == image.image_id
    assert len(data["suggestions"]) == 2
    assert data["pending"] == 2


@pytest.mark.asyncio
async def test_get_suggestions_requires_auth(client: AsyncClient):
    """Test that endpoint requires authentication"""
    response = await client.get("/api/v1/images/123/tag-suggestions")
    assert response.status_code == 401
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/api/v1/test_tag_suggestions.py::test_get_suggestions_for_image -v`

Expected: FAIL with 404 Not Found (route doesn't exist yet)

**Step 3: Write minimal implementation**

Create new router file:

```python
# app/api/v1/tag_suggestions.py

"""
Tag Suggestions API Endpoints
"""

from typing import Literal
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func

from app.core.database import get_db
from app.core.auth import get_current_user
from app.core.permissions import check_permission, Permission
from app.models.user import Users
from app.models.tag_suggestion import TagSuggestion
from app.models.tag import Tags
from app.models.image import Images
from app.schemas.tag_suggestion import (
    TagSuggestionsListResponse,
    TagSuggestionResponse
)
from app.schemas.tag import TagResponse


router = APIRouter()


@router.get("/images/{image_id}/tag-suggestions", response_model=TagSuggestionsListResponse)
async def get_tag_suggestions(
    image_id: int,
    status: Literal["pending", "approved", "rejected"] | None = None,
    db: AsyncSession = Depends(get_db),
    current_user: Users = Depends(get_current_user)
):
    """
    Get tag suggestions for an image.

    Permissions:
    - Image uploader can view their own suggestions
    - Moderators can view all suggestions
    """
    # Check if image exists
    result = await db.execute(
        select(Images).where(Images.image_id == image_id)
    )
    image = result.scalar_one_or_none()
    if not image:
        raise HTTPException(status_code=404, detail="Image not found")

    # Check permissions
    is_owner = image.user_id == current_user.user_id
    is_moderator = check_permission(current_user, Permission.IMAGE_TAG_ADD)

    if not is_owner and not is_moderator:
        raise HTTPException(
            status_code=403,
            detail="You can only view suggestions for your own images"
        )

    # Build query
    query = select(TagSuggestion).where(TagSuggestion.image_id == image_id)
    if status:
        query = query.where(TagSuggestion.status == status)

    result = await db.execute(query.order_by(TagSuggestion.confidence.desc()))
    suggestions = result.scalars().all()

    # Get tag details for each suggestion
    suggestion_responses = []
    for sugg in suggestions:
        tag_result = await db.execute(
            select(Tags).where(Tags.tag_id == sugg.tag_id)
        )
        tag = tag_result.scalar_one()

        suggestion_responses.append(
            TagSuggestionResponse(
                suggestion_id=sugg.suggestion_id,
                tag=TagResponse.from_orm(tag),
                confidence=sugg.confidence,
                model_source=sugg.model_source,
                status=sugg.status,
                created_at=sugg.created_at,
                reviewed_at=sugg.reviewed_at
            )
        )

    # Count by status
    status_counts = await db.execute(
        select(
            TagSuggestion.status,
            func.count(TagSuggestion.suggestion_id)
        )
        .where(TagSuggestion.image_id == image_id)
        .group_by(TagSuggestion.status)
    )

    counts = {"pending": 0, "approved": 0, "rejected": 0}
    for status_val, count in status_counts:
        counts[status_val] = count

    return TagSuggestionsListResponse(
        image_id=image_id,
        suggestions=suggestion_responses,
        total=len(suggestions),
        **counts
    )
```

Add to main images router:

```python
# app/api/v1/images.py

# Add this import at top
from app.api.v1 import tag_suggestions

# Add this at the bottom to include the tag suggestions routes
app.include_router(
    tag_suggestions.router,
    prefix="/api/v1",
    tags=["tag-suggestions"]
)
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/api/v1/test_tag_suggestions.py::test_get_suggestions_for_image -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/api/v1/tag_suggestions.py app/api/v1/images.py tests/api/v1/test_tag_suggestions.py
git commit -m "feat: add GET tag suggestions endpoint

- GET /api/v1/images/{image_id}/tag-suggestions
- Filter by status (pending/approved/rejected)
- Permission check: owner or moderator only
- Returns suggestions sorted by confidence"
```

---

### Task 4.2: Review Suggestions Endpoint

**Files:**
- Modify: `app/api/v1/tag_suggestions.py`
- Test: `tests/api/v1/test_tag_suggestions.py`

**Step 1: Write the failing test**

```python
# tests/api/v1/test_tag_suggestions.py (add to existing file)

@pytest.mark.asyncio
async def test_approve_suggestion_creates_tag_link(client: AsyncClient, db_session):
    """Test POST /api/v1/images/{image_id}/tag-suggestions/review (approve)"""
    # Create test data
    user = Users(username="test", email="test@example.com", password="hashed")
    db_session.add(user)
    await db_session.flush()

    image = Images(
        filename="test",
        ext="jpg",
        user_id=user.user_id,
        md5_hash="abc123",
        filesize=1024,
        width=800,
        height=600
    )
    db_session.add(image)
    await db_session.flush()

    tag = Tags(title="long hair", type=1, user_id=user.user_id)
    db_session.add(tag)
    await db_session.flush()

    suggestion = TagSuggestion(
        image_id=image.image_id,
        tag_id=tag.tag_id,
        confidence=0.92,
        model_source="custom_theme",
        model_version="v1",
        status="pending"
    )
    db_session.add(suggestion)
    await db_session.commit()

    # Approve suggestion
    response = await client.post(
        f"/api/v1/images/{image.image_id}/tag-suggestions/review",
        json={
            "suggestions": [
                {"suggestion_id": suggestion.suggestion_id, "action": "approve"}
            ]
        },
        headers={"Authorization": f"Bearer {get_auth_token(user)}"}
    )

    assert response.status_code == 200
    data = response.json()
    assert data["approved"] == 1
    assert data["rejected"] == 0

    # Verify TagLink was created
    from app.models.tag_link import TagLinks
    result = await db_session.execute(
        select(TagLinks).where(
            TagLinks.image_id == image.image_id,
            TagLinks.tag_id == tag.tag_id
        )
    )
    tag_link = result.scalar_one_or_none()
    assert tag_link is not None

    # Verify suggestion status updated
    await db_session.refresh(suggestion)
    assert suggestion.status == "approved"
    assert suggestion.reviewed_by_user_id == user.user_id


@pytest.mark.asyncio
async def test_reject_suggestion(client: AsyncClient, db_session):
    """Test POST /api/v1/images/{image_id}/tag-suggestions/review (reject)"""
    # Similar setup...

    response = await client.post(
        f"/api/v1/images/{image.image_id}/tag-suggestions/review",
        json={
            "suggestions": [
                {"suggestion_id": suggestion.suggestion_id, "action": "reject"}
            ]
        },
        headers={"Authorization": f"Bearer {get_auth_token(user)}"}
    )

    assert response.status_code == 200
    data = response.json()
    assert data["rejected"] == 1

    # Verify suggestion status updated but NO TagLink created
    await db_session.refresh(suggestion)
    assert suggestion.status == "rejected"
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/api/v1/test_tag_suggestions.py::test_approve_suggestion_creates_tag_link -v`

Expected: FAIL (route doesn't exist)

**Step 3: Write minimal implementation**

```python
# app/api/v1/tag_suggestions.py (add to existing file)

from datetime import datetime
from app.models.tag_link import TagLinks
from app.schemas.tag_suggestion import (
    ReviewSuggestionsRequest,
    ReviewSuggestionsResponse
)


@router.post("/images/{image_id}/tag-suggestions/review", response_model=ReviewSuggestionsResponse)
async def review_tag_suggestions(
    image_id: int,
    request: ReviewSuggestionsRequest,
    db: AsyncSession = Depends(get_db),
    current_user: Users = Depends(get_current_user)
):
    """
    Approve or reject tag suggestions.

    Permissions:
    - Requires IMAGE_TAG_ADD permission
    - Users can only review suggestions for their own images (unless moderator)
    """
    # Check if image exists
    result = await db.execute(
        select(Images).where(Images.image_id == image_id)
    )
    image = result.scalar_one_or_none()
    if not image:
        raise HTTPException(status_code=404, detail="Image not found")

    # Check permissions
    is_owner = image.user_id == current_user.user_id
    is_moderator = check_permission(current_user, Permission.IMAGE_TAG_ADD)

    if not is_owner and not is_moderator:
        raise HTTPException(
            status_code=403,
            detail="You can only review suggestions for your own images"
        )

    approved_count = 0
    rejected_count = 0
    errors = []

    for review_item in request.suggestions:
        try:
            # Get suggestion
            result = await db.execute(
                select(TagSuggestion).where(
                    TagSuggestion.suggestion_id == review_item.suggestion_id,
                    TagSuggestion.image_id == image_id
                )
            )
            suggestion = result.scalar_one_or_none()

            if not suggestion:
                errors.append(f"Suggestion {review_item.suggestion_id} not found")
                continue

            if review_item.action == "approve":
                # Check if TagLink already exists
                result = await db.execute(
                    select(TagLinks).where(
                        TagLinks.image_id == image_id,
                        TagLinks.tag_id == suggestion.tag_id
                    )
                )
                existing_link = result.scalar_one_or_none()

                if not existing_link:
                    # Create TagLink
                    tag_link = TagLinks(
                        image_id=image_id,
                        tag_id=suggestion.tag_id,
                        user_id=current_user.user_id
                    )
                    db.add(tag_link)

                # Update suggestion status
                suggestion.status = "approved"
                suggestion.reviewed_at = datetime.utcnow()
                suggestion.reviewed_by_user_id = current_user.user_id
                approved_count += 1

            elif review_item.action == "reject":
                suggestion.status = "rejected"
                suggestion.reviewed_at = datetime.utcnow()
                suggestion.reviewed_by_user_id = current_user.user_id
                rejected_count += 1

        except Exception as e:
            errors.append(f"Error processing suggestion {review_item.suggestion_id}: {str(e)}")

    await db.commit()

    return ReviewSuggestionsResponse(
        approved=approved_count,
        rejected=rejected_count,
        errors=errors
    )
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/api/v1/test_tag_suggestions.py::test_approve_suggestion_creates_tag_link -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/api/v1/tag_suggestions.py tests/api/v1/test_tag_suggestions.py
git commit -m "feat: add review tag suggestions endpoint

- POST /api/v1/images/{image_id}/tag-suggestions/review
- Approve action creates TagLink and updates status
- Reject action only updates status
- Permission check: IMAGE_TAG_ADD required
- Batch review support (multiple suggestions at once)"
```

---

## Phase 5: Background Jobs

### Task 5.1: Create Tag Suggestion Generation Job

**Files:**
- Create: `app/tasks/ml_jobs.py`
- Test: `tests/tasks/test_ml_jobs.py`

**Step 1: Write the failing test**

```python
# tests/tasks/test_ml_jobs.py

import pytest
from app.tasks.ml_jobs import generate_tag_suggestions
from app.models.image import Images
from app.models.user import Users
from app.models.tag_suggestion import TagSuggestion
from app.services.ml_service import MLTagSuggestionService
from sqlalchemy import select


@pytest.mark.asyncio
async def test_generate_tag_suggestions_job(db_session):
    """Test tag suggestion generation background job"""
    # Create test image
    user = Users(username="test", email="test@example.com", password="hashed")
    db_session.add(user)
    await db_session.flush()

    image = Images(
        filename="test",
        ext="jpg",
        user_id=user.user_id,
        md5_hash="abc123",
        filesize=1024,
        width=800,
        height=600
    )
    db_session.add(image)
    await db_session.commit()

    # Create ML service
    ml_service = MLTagSuggestionService()
    await ml_service.load_models()

    # Run job
    ctx = {"ml_service": ml_service}
    result = await generate_tag_suggestions(ctx, image.image_id)

    assert result["status"] == "completed"
    assert result["suggestions_created"] > 0

    # Verify suggestions in database
    query = select(TagSuggestion).where(TagSuggestion.image_id == image.image_id)
    result = await db_session.execute(query)
    suggestions = result.scalars().all()

    assert len(suggestions) > 0
    assert all(s.status == "pending" for s in suggestions)


@pytest.mark.asyncio
async def test_job_skips_if_suggestions_exist(db_session):
    """Test that job doesn't regenerate existing suggestions"""
    # Create image with existing suggestion
    user = Users(username="test", email="test@example.com", password="hashed")
    db_session.add(user)
    await db_session.flush()

    image = Images(
        filename="test",
        ext="jpg",
        user_id=user.user_id,
        md5_hash="abc123",
        filesize=1024,
        width=800,
        height=600
    )
    db_session.add(image)
    await db_session.flush()

    # Pre-existing suggestion
    existing = TagSuggestion(
        image_id=image.image_id,
        tag_id=46,
        confidence=0.9,
        model_source="custom_theme",
        model_version="v1",
        status="pending"
    )
    db_session.add(existing)
    await db_session.commit()

    # Run job without force_regenerate
    ml_service = MLTagSuggestionService()
    await ml_service.load_models()
    ctx = {"ml_service": ml_service}

    result = await generate_tag_suggestions(ctx, image.image_id, force_regenerate=False)

    assert result["status"] == "skipped"
    assert result["reason"] == "suggestions_exist"
```

**Step 2: Run test to verify it fails**

Run: `uv run pytest tests/tasks/test_ml_jobs.py -v`

Expected: FAIL with "ModuleNotFoundError"

**Step 3: Write minimal implementation**

```python
# app/tasks/ml_jobs.py

"""
ML Background Jobs

Arq background jobs for ML tag suggestion generation.
"""

from typing import Dict
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.core.database import get_async_session
from app.models.image import Images
from app.models.tag_suggestion import TagSuggestion
from app.services.ml_service import MLTagSuggestionService
from app.services.tag_resolver import resolve_tag_relationships
from app.config import settings


async def generate_tag_suggestions(
    ctx: Dict,
    image_id: int,
    force_regenerate: bool = False
) -> Dict:
    """
    Generate ML tag suggestions for an image.

    Triggered after image upload and processing completes.
    Runs both models, merges predictions, stores in database.

    Args:
        ctx: Worker context (contains ml_service)
        image_id: ID of image to generate suggestions for
        force_regenerate: If True, regenerate even if suggestions exist

    Returns:
        Dict with status and suggestions_created count
    """
    async with get_async_session() as db:
        # 1. Fetch image
        result = await db.execute(
            select(Images).where(Images.image_id == image_id)
        )
        image = result.scalar_one_or_none()
        if not image:
            raise ValueError(f"Image {image_id} not found")

        # 2. Check if suggestions already exist
        if not force_regenerate:
            result = await db.execute(
                select(TagSuggestion).where(TagSuggestion.image_id == image_id)
            )
            if result.scalar_one_or_none():
                return {"status": "skipped", "reason": "suggestions_exist"}

        # 3. Get image file path
        # Note: This assumes images are stored in STORAGE_PATH
        image_path = f"{settings.STORAGE_PATH}/{image.filename}.{image.ext}"

        # 4. Run ML inference
        ml_service = ctx["ml_service"]
        suggestions = await ml_service.generate_suggestions(image_path)

        # 5. Resolve aliases and hierarchy
        suggestions = await resolve_tag_relationships(db, suggestions)

        # 6. Filter by confidence thresholds (already done in ML service, but double-check)
        # Theme tags: min 0.6, Source: min 0.7, Character: min 0.75
        # For now, we're using a simple threshold since we don't have tag type info yet
        # TODO: Add tag type filtering once we integrate with Tags table

        # 7. Store in database
        created_count = 0
        for sugg in suggestions:
            # Check if this specific suggestion already exists
            result = await db.execute(
                select(TagSuggestion).where(
                    TagSuggestion.image_id == image_id,
                    TagSuggestion.tag_id == sugg["tag_id"]
                )
            )
            existing = result.scalar_one_or_none()

            if existing and not force_regenerate:
                continue  # Skip duplicates

            if existing and force_regenerate:
                # Update existing
                existing.confidence = sugg["confidence"]
                existing.model_source = sugg["model_source"]
                existing.status = "pending"  # Reset to pending
            else:
                # Create new
                tag_suggestion = TagSuggestion(
                    image_id=image_id,
                    tag_id=sugg["tag_id"],
                    confidence=sugg["confidence"],
                    model_source=sugg["model_source"],
                    model_version=sugg.get("model_version", "v1"),
                    status="pending"
                )
                db.add(tag_suggestion)
                created_count += 1

        await db.commit()

        return {
            "status": "completed",
            "suggestions_created": created_count,
            "image_id": image_id
        }
```

**Step 4: Run test to verify it passes**

Run: `uv run pytest tests/tasks/test_ml_jobs.py -v`

Expected: PASS

**Step 5: Commit**

```bash
git add app/tasks/ml_jobs.py tests/tasks/test_ml_jobs.py
git commit -m "feat: add tag suggestion generation background job

- Arq job: generate_tag_suggestions(image_id)
- Runs ML inference with both models
- Resolves tag aliases and hierarchies
- Stores suggestions in database
- Skips if suggestions already exist (unless force_regenerate)"
```

---

### Task 5.2: Register Job in Worker

**Files:**
- Modify: `app/tasks/worker.py`

**Step 1: Add ML service to worker context**

```python
# app/tasks/worker.py

# Add imports at top
from app.services.ml_service import MLTagSuggestionService
from app.tasks.ml_jobs import generate_tag_suggestions

# Modify startup function
async def startup(ctx: dict):
    """
    Worker startup - load ML models into memory.

    Models are loaded once and cached for the lifetime of the worker.
    """
    # Existing Redis connection setup (if any)
    # ...

    # Load ML models
    ctx["ml_service"] = MLTagSuggestionService()
    await ctx["ml_service"].load_models()
    logger.info("ML tag suggestion models loaded")


async def shutdown(ctx: dict):
    """Worker shutdown - cleanup resources"""
    if "ml_service" in ctx:
        await ctx["ml_service"].cleanup()
        logger.info("ML models unloaded")


# Modify WorkerSettings
class WorkerSettings:
    """Arq worker settings"""

    functions = [
        # Existing jobs
        generate_image_variants,
        add_to_iqdb,
        recalculate_rating,
        # New job
        generate_tag_suggestions,
    ]

    on_startup = startup
    on_shutdown = shutdown

    # Adjust for ML workload
    max_jobs = 4  # Limit concurrent ML jobs (memory-intensive)
    job_timeout = 300  # 5 minutes (ML inference can be slow)
```

**Step 2: Verify worker starts successfully**

Run: `uv run arq app.tasks.worker.WorkerSettings`

Expected: Worker starts, logs "ML tag suggestion models loaded"

**Step 3: Commit**

```bash
git add app/tasks/worker.py
git commit -m "feat: register ML tag suggestion job in Arq worker

- Load ML models at worker startup
- Register generate_tag_suggestions job
- Adjust max_jobs and timeout for ML workload
- Cleanup models on shutdown"
```

---

### Task 5.3: Integrate with Upload Flow

**Files:**
- Modify: `app/api/v1/images.py`

**Step 1: Add to upload endpoint**

```python
# app/api/v1/images.py

# Find the upload endpoint and add after existing job enqueues:

@router.post("/", response_model=ImageResponse)
async def upload_image(
    # ... existing params ...
    queue: ArqRedis = Depends(get_arq_queue)
):
    # ... existing upload logic ...

    # After image saved and other jobs enqueued:

    # 1. Generate variants (existing)
    await queue.enqueue_job("generate_image_variants", image_id=image.image_id)

    # 2. Add to IQDB (existing)
    await queue.enqueue_job("add_to_iqdb", image_id=image.image_id)

    # 3. Generate tag suggestions (NEW)
    suggestion_job = await queue.enqueue_job(
        "generate_tag_suggestions",
        image_id=image.image_id,
        _defer_by=30  # Wait 30s for image processing to finish
    )

    # ... existing return statement ...
    # Optionally add suggestion_job_id to response
```

**Step 2: Test upload triggers suggestion job**

Manual test:
1. Start worker: `uv run arq app.tasks.worker.WorkerSettings`
2. Upload image via API
3. Check worker logs for "tag_suggestions_generated"
4. Query database to verify suggestions were created

**Step 3: Commit**

```bash
git add app/api/v1/images.py
git commit -m "feat: integrate tag suggestion generation with upload flow

- Enqueue generate_tag_suggestions job after image upload
- Defer job by 30s to allow image processing to complete
- Suggestions generated automatically for all new uploads"
```

---

## Phase 6: Testing & Documentation

### Task 6.1: Integration Tests

**Files:**
- Create: `tests/integration/test_tag_suggestion_workflow.py`

**Step 1: Write end-to-end test**

```python
# tests/integration/test_tag_suggestion_workflow.py

import pytest
from httpx import AsyncClient
from app.models.user import Users
from app.models.tag_suggestion import TagSuggestion
from sqlalchemy import select


@pytest.mark.asyncio
async def test_full_tag_suggestion_workflow(client: AsyncClient, db_session, arq_worker):
    """
    Test complete workflow: upload → suggestion generation → review

    This is an integration test covering:
    1. Image upload
    2. Background job generates suggestions
    3. User fetches suggestions
    4. User approves suggestions
    5. TagLinks are created
    """
    # 1. Upload image
    user = Users(username="test", email="test@example.com", password="hashed")
    db_session.add(user)
    await db_session.commit()

    with open("tests/fixtures/sample_image.jpg", "rb") as f:
        image_data = f.read()

    response = await client.post(
        "/api/v1/images",
        files={"file": ("test.jpg", image_data, "image/jpeg")},
        headers={"Authorization": f"Bearer {get_auth_token(user)}"}
    )

    assert response.status_code == 200
    image_id = response.json()["image_id"]

    # 2. Wait for background job to complete
    await arq_worker.run_check()  # Process queued jobs

    # 3. Fetch suggestions
    response = await client.get(
        f"/api/v1/images/{image_id}/tag-suggestions",
        headers={"Authorization": f"Bearer {get_auth_token(user)}"}
    )

    assert response.status_code == 200
    data = response.json()
    assert len(data["suggestions"]) > 0
    suggestions = data["suggestions"]

    # 4. Approve first 3 suggestions
    review_request = {
        "suggestions": [
            {"suggestion_id": s["suggestion_id"], "action": "approve"}
            for s in suggestions[:3]
        ]
    }

    response = await client.post(
        f"/api/v1/images/{image_id}/tag-suggestions/review",
        json=review_request,
        headers={"Authorization": f"Bearer {get_auth_token(user)}"}
    )

    assert response.status_code == 200
    assert response.json()["approved"] == 3

    # 5. Verify TagLinks were created
    from app.models.tag_link import TagLinks
    result = await db_session.execute(
        select(TagLinks).where(TagLinks.image_id == image_id)
    )
    tag_links = result.scalars().all()

    assert len(tag_links) >= 3  # At least the 3 we approved
```

**Step 2: Run test**

Run: `uv run pytest tests/integration/test_tag_suggestion_workflow.py -v`

Expected: PASS

**Step 3: Commit**

```bash
git add tests/integration/test_tag_suggestion_workflow.py
git commit -m "test: add end-to-end tag suggestion workflow test

- Tests complete flow from upload to approval
- Verifies background job generates suggestions
- Verifies API endpoints work together
- Verifies TagLinks are created on approval"
```

---

### Task 6.2: Update API Documentation

**Files:**
- Modify: `README.md` or `docs/API.md`

**Step 1: Document new endpoints**

Add section to API documentation:

```markdown
## Tag Suggestions

### Get Tag Suggestions for Image

```
GET /api/v1/images/{image_id}/tag-suggestions
```

Returns ML-generated tag suggestions for an image.

**Query Parameters:**
- `status` (optional): Filter by status (`pending`, `approved`, `rejected`)

**Response:**
```json
{
  "image_id": 12345,
  "suggestions": [...],
  "total": 15,
  "pending": 12,
  "approved": 3,
  "rejected": 0
}
```

### Review Tag Suggestions

```
POST /api/v1/images/{image_id}/tag-suggestions/review
```

Approve or reject tag suggestions.

**Request Body:**
```json
{
  "suggestions": [
    {"suggestion_id": 1, "action": "approve"},
    {"suggestion_id": 2, "action": "reject"}
  ]
}
```

**Response:**
```json
{
  "approved": 1,
  "rejected": 1,
  "errors": []
}
```
```

**Step 2: Commit**

```bash
git add docs/API.md
git commit -m "docs: add tag suggestions API documentation

- Document GET /images/{id}/tag-suggestions endpoint
- Document POST /images/{id}/tag-suggestions/review endpoint
- Include request/response examples"
```

---

## Verification & Next Steps

### Final Verification Checklist

After completing all tasks, verify:

- [ ] All tests pass: `uv run pytest -v`
- [ ] Database migrations apply cleanly: `uv run alembic upgrade head`
- [ ] Worker starts without errors: `uv run arq app.tasks.worker.WorkerSettings`
- [ ] Upload endpoint triggers suggestion job
- [ ] Suggestions are stored in database
- [ ] API endpoints return expected responses
- [ ] Tag aliases are resolved correctly
- [ ] Parent tags are added from hierarchy

### Next Phase: Real ML Models

This plan implements Phase 1 with mock ML models. For Phase 2 (real models):

1. **Obtain model files** - Download WD14 Tagger ONNX model
2. **Update ML service** - Replace MockModel with ONNX Runtime inference
3. **Tag mapping** - Populate tag_mappings table with Danbooru → internal mappings
4. **Train custom model** - Train custom theme classifier on your 359 tags
5. **Deploy & test** - Compare real model performance vs mock

See design document for detailed Phase 2 plan.

---

**Plan saved to:** `docs/plans/2025-12-04-tag-suggestion-system-implementation.md`

**Total estimated time:** 8-12 hours for Phase 1 (mock implementation)

**Commits:** ~20 small, focused commits following TDD workflow
